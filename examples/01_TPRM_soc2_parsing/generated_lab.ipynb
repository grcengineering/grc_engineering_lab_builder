{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOC 2 Type 2 Document Analysis Learning Lab\n",
    "## Parsing Unstructured Vendor Documentation\n",
    "\n",
    "**Generated for:** TPRM Lead, B2B SaaS Tech Company\n",
    "\n",
    "**Your Goal:** Transform 3+ hours of manual SOC 2 reading per vendor into 30-45 minutes of structured analysis\n",
    "\n",
    "**Why This Matters for Your Role:** With 500+ vendors and manual reviews creating bottlenecks, automating document parsing will free you to focus on risk assessment and stakeholder communication‚Äîyour strongest areas.\n",
    "\n",
    "**Technical Leap:** Moving from \"reading PDFs\" ‚Üí \"extracting structured data programmatically\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÖ 12-Week Progressive Build\n",
    "*3 hours/week = 36 total hours*\n",
    "\n",
    "### Phase 1: Foundation (Weeks 1-2)\n",
    "- Week 1: Document Structure Mapping\n",
    "- Week 2: Manual Baseline Measurement\n",
    "\n",
    "### Phase 2: Core Skills (Weeks 3-5)\n",
    "- Week 3: Your First Python PDF Parser\n",
    "- Week 4: Finding Specific Sections\n",
    "- Week 5: Extracting Structured Data\n",
    "\n",
    "### Phase 3: Integration (Weeks 6-8)\n",
    "- Week 6: Batch Processing Multiple PDFs\n",
    "- Week 7: Google Sheets Integration\n",
    "- Week 8: Building Dashboard\n",
    "\n",
    "### Phase 4: Advanced (Weeks 9-10)\n",
    "- Week 9: Exception Pattern Analysis\n",
    "- Week 10: Automated Risk Scoring\n",
    "\n",
    "### Phase 5: Production (Weeks 11-12)\n",
    "- Week 11: Production Runbook & Documentation\n",
    "- Week 12: Stakeholder Presentation & Metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Document Structure Mapping\n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** Beginner (No coding)\n",
    "\n",
    "## üéØ Learning Goals\n",
    "- [ ] Understand SOC 2 Type 2 report structure\n",
    "- [ ] Identify the data points you always need to extract\n",
    "- [ ] Map your current manual process\n",
    "- [ ] Identify time-consuming pain points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 1: Visual Mapping Exercise (90 mins)\n",
    "\n",
    "Open a recent SOC 2 report and create a Google Doc with this template:\n",
    "\n",
    "```\n",
    "DOCUMENT: [Vendor Name] SOC 2 Type 2\n",
    "\n",
    "SECTIONS I ALWAYS CHECK:\n",
    "‚ñ° Opinion letter (page __)\n",
    "‚ñ° Control descriptions (pages __)\n",
    "‚ñ° Testing results (pages __)\n",
    "‚ñ° Exceptions/deviations (pages __)\n",
    "‚ñ° Subservice organizations (pages __)\n",
    "\n",
    "KEY DATA POINTS I EXTRACT:\n",
    "- Report period: [dates]\n",
    "- Opinion type: [Unqualified/Qualified/Adverse]\n",
    "- Trust Service Categories: [List]\n",
    "- Number of controls tested: [#]\n",
    "- Exceptions found: [#]\n",
    "- Complementary user entity controls: [Y/N, how many]\n",
    "\n",
    "RED FLAGS I LOOK FOR:\n",
    "- [List your current mental checklist]\n",
    "\n",
    "TIME SPENT:\n",
    "- Finding these sections: __ mins\n",
    "- Reading opinion: __ mins\n",
    "- Reviewing exceptions: __ mins\n",
    "- Assessing CUECs: __ mins\n",
    "```\n",
    "\n",
    "**Repeat this for 2 more vendors to identify patterns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 2: Create Your \"Extraction Checklist\" (30 mins)\n",
    "\n",
    "Build a Google Sheet with columns for the data points you always need:\n",
    "\n",
    "| Vendor | Report Period | Opinion | TSC Covered | Controls Tested | Exceptions | CUECs | Review Time |\n",
    "|--------|---------------|---------|-------------|-----------------|------------|-------|-------------|\n",
    "| Vendor A | ... | ... | ... | ... | ... | ... | 3.5 hours |\n",
    "\n",
    "**This becomes your target output structure for automation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Week 1 Deliverable\n",
    "\n",
    "- [ ] Structured template showing what you need from every SOC 2 report\n",
    "- [ ] Google Sheet with extraction checklist columns\n",
    "- [ ] Documented pain points (where does time go?)\n",
    "\n",
    "**üí° Key Insight:** You should now have a clear picture of WHAT to automate. Next week, we'll measure HOW LONG it takes manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Week 2: Manual Baseline Measurement\n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** Beginner (No coding)\n",
    "\n",
    "## üéØ Learning Goals\n",
    "- [ ] Establish baseline metrics (current state)\n",
    "- [ ] Identify automation opportunities\n",
    "- [ ] Document error-prone tasks\n",
    "- [ ] Prioritize what to automate first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Timed Review Session (2.5 hours)\n",
    "\n",
    "Review 3 new SOC 2 reports using your extraction checklist from Week 1.\n",
    "\n",
    "**Set a timer for each report and track:**\n",
    "- Total time per report\n",
    "- Time finding each section\n",
    "- Time reading vs. copy-pasting\n",
    "- Any data points you missed initially\n",
    "\n",
    "**Document in a Google Doc:**\n",
    "\n",
    "```\n",
    "MANUAL REVIEW PAIN POINTS\n",
    "\n",
    "Most time-consuming tasks:\n",
    "1. Finding exception details scattered across pages 45-89: 45 mins\n",
    "2. Determining which Trust Service Categories are covered: 15 mins\n",
    "3. Copy-pasting into tracking spreadsheet: 20 mins\n",
    "\n",
    "Most error-prone tasks:\n",
    "1. Missing complementary controls in dense paragraphs\n",
    "2. Miscounting number of exceptions\n",
    "\n",
    "Most tedious tasks:\n",
    "1. Finding the same sections in every report\n",
    "2. Formatting data consistently in spreadsheet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Week 2 Deliverable\n",
    "\n",
    "- [ ] Baseline metrics: Average time per report = ____ hours\n",
    "- [ ] Prioritized list of automation targets\n",
    "- [ ] Pain point documentation\n",
    "\n",
    "**üí° Key Insight:** You now have concrete numbers to show time savings after automation. Keep these metrics‚Äîyou'll present them to your manager in Week 12!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Week 3: Your First Python PDF Parser\n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "## üéØ Learning Goals\n",
    "- [ ] Set up Python environment\n",
    "- [ ] Install PDF processing library\n",
    "- [ ] Write your first PDF extraction script\n",
    "- [ ] Understand PDF text extraction quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (30 mins)\n",
    "\n",
    "Install the required library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this once to install PyPDF2\n",
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import PyPDF2\n",
    "import sys\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your First PDF Extraction Script (2 hours)\n",
    "\n",
    "Let's build a function that extracts all text from a PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Opens a PDF and extracts all text.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to your PDF file\n",
    "    \n",
    "    Returns:\n",
    "        String containing all the text\n",
    "    \"\"\"\n",
    "    # Open the PDF file in \"read binary\" mode\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        # Create a PDF reader object (this does the heavy lifting)\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Get the total number of pages\n",
    "        num_pages = len(pdf_reader.pages)\n",
    "        print(f\"üìÑ Found {num_pages} pages in the document\")\n",
    "        \n",
    "        # Create an empty string to store all the text\n",
    "        full_text = \"\"\n",
    "        \n",
    "        # Loop through each page\n",
    "        for page_num in range(num_pages):\n",
    "            # Get this specific page\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            \n",
    "            # Extract text from this page\n",
    "            page_text = page.extract_text()\n",
    "            \n",
    "            # Add it to our full text with a page marker\n",
    "            full_text += f\"\\n--- PAGE {page_num + 1} ---\\n\"\n",
    "            full_text += page_text\n",
    "        \n",
    "        return full_text\n",
    "\n",
    "print(\"‚úÖ Function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a Real SOC 2 Report\n",
    "\n",
    "**Replace the path below with YOUR actual SOC 2 PDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THIS PATH to your SOC 2 PDF location\n",
    "pdf_path = \"/path/to/your/soc2_report.pdf\"\n",
    "\n",
    "print(f\"üîç Extracting text from: {pdf_path}\")\n",
    "\n",
    "# Extract the text\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Show statistics\n",
    "print(f\"‚úÖ Extraction complete!\")\n",
    "print(f\"üìä Total characters: {len(extracted_text):,}\")\n",
    "print(f\"üìä Total lines: {len(extracted_text.splitlines()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the Extracted Text\n",
    "\n",
    "Let's look at the first 1000 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÑ PREVIEW OF EXTRACTED TEXT:\")\n",
    "print(\"=\"*50)\n",
    "print(extracted_text[:1000])\n",
    "print(\"=\"*50)\n",
    "print(\"\\n[...] (showing first 1000 characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Text File\n",
    "\n",
    "So you can review extraction quality in a text editor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output filename\n",
    "output_file = pdf_path.replace('.pdf', '_extracted.txt')\n",
    "\n",
    "# Write to file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(extracted_text)\n",
    "\n",
    "print(f\"‚úÖ Text saved to: {output_file}\")\n",
    "print(f\"üí° Open this file in TextEdit or VS Code to review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Exercise (45 mins)\n",
    "\n",
    "Compare the extracted text to the original PDF:\n",
    "\n",
    "**What extracted well?**\n",
    "- Paragraphs in the opinion letter\n",
    "- Control descriptions\n",
    "- [Add your observations]\n",
    "\n",
    "**What was messy?**\n",
    "- Tables lost their structure\n",
    "- Multi-column layouts ran together\n",
    "- [Add your observations]\n",
    "\n",
    "**What was missing?**\n",
    "- Page headers/footers\n",
    "- [Add your observations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Week 3 Deliverable\n",
    "\n",
    "- [ ] Working script that extracts text from any SOC 2 PDF\n",
    "- [ ] Extracted text file saved for review\n",
    "- [ ] Documented observations about extraction quality\n",
    "\n",
    "**üí° Key Insight:** Not all PDFs extract perfectly, but it's good enough to work with! Next week, we'll make this smarter by finding specific sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Week 4: Finding Specific Sections\n",
    "**Time:** 3 hours  \n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "## üéØ Learning Goals\n",
    "- [ ] Use regular expressions to find keywords\n",
    "- [ ] Locate specific sections (Opinion, Exceptions, CUECs)\n",
    "- [ ] Extract context around matches\n",
    "- [ ] Save findings to structured format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Additional Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Regular expressions for pattern matching\n",
    "\n",
    "print(\"‚úÖ Regular expressions module imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Section Keywords\n",
    "\n",
    "Based on your Week 1 mapping, define the keywords for sections you care about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sections you care about\n",
    "SECTION_KEYWORDS = {\n",
    "    'Opinion Letter': [\n",
    "        'independent service auditor',\n",
    "        'in our opinion',\n",
    "        'unqualified opinion',\n",
    "        'qualified opinion'\n",
    "    ],\n",
    "    'Report Period': [\n",
    "        'report period',\n",
    "        'examination period',\n",
    "        'from .* to .*202[0-9]'  # Regex to catch date ranges\n",
    "    ],\n",
    "    'Exceptions': [\n",
    "        'exception',\n",
    "        'deviation',\n",
    "        'deficiency',\n",
    "        'did not operate effectively'\n",
    "    ],\n",
    "    'Complementary Controls': [\n",
    "        'complementary user entity controls',\n",
    "        'CUEC',\n",
    "        'user entity controls',\n",
    "        'complementary controls'\n",
    "    ],\n",
    "    'Subservice Organizations': [\n",
    "        'subservice organi[zs]ation',\n",
    "        'carve.?out',\n",
    "        'inclusive method',\n",
    "        'carved.?out'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Section keywords defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Section Finder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sections(text, section_keywords):\n",
    "    \"\"\"\n",
    "    Finds sections in the text based on keywords.\n",
    "    \n",
    "    Args:\n",
    "        text: The full extracted text\n",
    "        section_keywords: Dictionary of section names and their keywords\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with section names and their locations\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for section_name, keywords in section_keywords.items():\n",
    "        print(f\"\\nüîç Looking for: {section_name}\")\n",
    "        \n",
    "        found_locations = []\n",
    "        for keyword in keywords:\n",
    "            # Case-insensitive search\n",
    "            pattern = re.compile(keyword, re.IGNORECASE)\n",
    "            matches = pattern.finditer(text)\n",
    "            \n",
    "            for match in matches:\n",
    "                # Get context (100 characters before and after)\n",
    "                start = max(0, match.start() - 100)\n",
    "                end = min(len(text), match.end() + 100)\n",
    "                context = text[start:end]\n",
    "                \n",
    "                found_locations.append({\n",
    "                    'keyword': keyword,\n",
    "                    'position': match.start(),\n",
    "                    'context': context\n",
    "                })\n",
    "        \n",
    "        results[section_name] = found_locations\n",
    "        print(f\"   Found {len(found_locations)} mentions\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Section finder function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Section Finder on Your SOC 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the extracted text from Week 3\n",
    "print(\"üìÑ Analyzing sections...\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Find all sections\n",
    "results = find_sections(extracted_text, SECTION_KEYWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file for review\n",
    "output_file = pdf_path.replace('.pdf', '_section_analysis.txt')\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"SOC 2 SECTION ANALYSIS\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    for section_name, locations in results.items():\n",
    "        f.write(f\"\\n{section_name.upper()}\\n\")\n",
    "        f.write(\"-\"*50 + \"\\n\")\n",
    "        \n",
    "        if locations:\n",
    "            for loc in locations:\n",
    "                f.write(f\"\\nKeyword: {loc['keyword']}\\n\")\n",
    "                f.write(f\"Context: ...{loc['context']}...\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        else:\n",
    "            f.write(\"‚ùå Not found\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Detailed analysis saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Week 4 Deliverable\n",
    "\n",
    "- [ ] Script that automatically finds your priority sections\n",
    "- [ ] Section analysis file showing all matches with context\n",
    "- [ ] Time comparison: Manual section finding vs. script\n",
    "\n",
    "**üí° Key Insight:** The script finds sections in seconds that would take 15-20 minutes manually. Next week, we'll extract structured data from these sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Week 5-12: Continue Building...\n",
    "\n",
    "**Note:** This notebook shows the structure for Weeks 1-4. The complete lab continues through Week 12 with:\n",
    "\n",
    "- **Week 5:** Extract structured data to CSV\n",
    "- **Week 6:** Batch process multiple PDFs\n",
    "- **Week 7:** Upload to Google Sheets automatically\n",
    "- **Week 8:** Build interactive dashboard\n",
    "- **Week 9:** Exception pattern analysis\n",
    "- **Week 10:** Automated risk scoring\n",
    "- **Week 11:** Production runbook\n",
    "- **Week 12:** Stakeholder presentation\n",
    "\n",
    "Each week builds on previous code with progressive complexity, hands-on exercises, and real deliverables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Next Steps\n",
    "\n",
    "1. **Complete Weeks 1-4** following this notebook\n",
    "2. **Test with 3 different SOC 2 reports** from different auditors\n",
    "3. **Document time savings** vs. manual process\n",
    "4. **Continue to Week 5** for structured data extraction\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [PyPDF2 Documentation](https://pypdf2.readthedocs.io/)\n",
    "- [Python Regular Expressions Guide](https://docs.python.org/3/library/re.html)\n",
    "- [SOC 2 Report Structure Overview](https://www.aicpa.org/soc4so)\n",
    "\n",
    "---\n",
    "\n",
    "## üí¨ Questions?\n",
    "\n",
    "Check the [main repository](../../README.md) or see other [example labs](../)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
